{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kyle Larson\n",
    "# File Name: OVERTRAINED.ipynb\n",
    "# License: GPL 3\n",
    "# Objective: The objective of this document is to demonstrate a simple neural network\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "#This function converts date and time from 'dd-Mth-yyyy hh:mm' to 'yyyymmddhhmm'\n",
    "def integer_Date_Time(string_1):\n",
    "    months = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "    string_2 =re.search(r'\\d+', string_1).group()\n",
    "    integer_date_time =int(string_2)*10000\n",
    "    for i in range(3):\n",
    "        string_1 = string_1.replace(string_2,'')\n",
    "        if(re.search(r'\\d+', string_1)):\n",
    "            string_2 = re.search(r'\\d+', string_1).group()\n",
    "        if i==0:\n",
    "            integer_date_time +=int(string_2)*100000000\n",
    "        if i==1:\n",
    "            integer_date_time +=int(string_2)*100\n",
    "        if i==2:\n",
    "            integer_date_time +=int(string_2)\n",
    "            regex = r'(?<=-)([\\w\\.-]+)- :(\\d+)'\n",
    "            match = re.search(regex, string_1)\n",
    "            if match: \n",
    "                for j in range(len(months)):\n",
    "                    if(re.match(match.group(1), months[j])):\n",
    "                        integer_date_time+=(j+1)*1000000\n",
    "    return integer_date_time\n",
    "\n",
    "#This function cleans Active Calories, Cycling Distance, Distance and Steps files\n",
    "#reading their raw data and writing it to smaller tidier files by day\n",
    "def clean_ACCDDS(data_source, i_loc, o_loc):\n",
    "    d ={ 'Time':[0] , data_source:[0] }\n",
    "    df = pandas.DataFrame(d, columns=['Time', data_source])\n",
    "    \n",
    "    T ='Time'\n",
    "    D =data_source\n",
    "    line_count =0\n",
    "    start_file_index =0\n",
    "    Nextdate =0\n",
    "    date =0\n",
    "    with open(i_loc+data_source+\".csv\", mode='r') as csv_file:\n",
    "    \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count =0\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if(line_count>0):\n",
    "                df = df.append({T:integer_Date_Time(row[1]),D:float(row[2])}, ignore_index=True)\n",
    "                Nextdate = df.loc[line_count][0] - (df.loc[line_count][0])%10000\n",
    "                #print(str(integer_Date_Time(row[1]))+\", \"+row[2])\n",
    "                if(line_count>1 and Nextdate-date >= 10000):\n",
    "                    with open(o_loc+data_source+str(Nextdate/10000)+\".csv\", mode='w') as outf:\n",
    "                        i =start_file_index\n",
    "                        outf.write(\"Time, \"+data_source+\"\\n\")\n",
    "                        while(i<line_count):\n",
    "                            outf.write(str(df.loc[i][0])+\", \"+str(df.loc[i][1])+\"\\n\")\n",
    "                            i +=1\n",
    "                    start_file_index = line_count\n",
    "            line_count +=1\n",
    "            date = Nextdate\n",
    "    return\n",
    "\n",
    "\n",
    "#___MAIN____\n",
    "dataSource = ['Active Calories', 'Cycling Distance', 'Distance', 'Steps']\n",
    "O_loc =r'C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\By Day\\\\'\n",
    "I_loc =r'C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\\\'\n",
    "for i in range(len(dataSource)):\n",
    "    clean_ACCDDS(dataSource[i], I_loc, O_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t='Time'\n",
    "h='HRV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____Borrowed from FileName:HRV_NN.ipynb this function imports the desired output HRV data\n",
    "def import_HRV(HR_source, timeStamp_S, timeStamp_E):\n",
    "    HRV =0\n",
    "    Running_Sum_HR =0\n",
    "    HRV_sampling_iter =0\n",
    "    prev_HR =0\n",
    "    HR_sampling_interval =10\n",
    "    dfs_HRV =[pandas.DataFrame()]\n",
    "    while(timeStamp_S < timeStamp_E):\n",
    "        with open(HR_source+str(timeStamp_S)+\".csv\", mode='r') as csv_file:\n",
    "\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count =0\n",
    "            df_HR = pandas.DataFrame()\n",
    "            df_HRV = pandas.DataFrame()\n",
    "            HRV_sampling_iter=0\n",
    "            Running_Sum_HR=0\n",
    "            for row in csv_reader:\n",
    "                if(line_count >0):\n",
    "                    df_HR = df_HR.append({t:float(row[0]), 'HR':float(row[1])}, ignore_index=True)\n",
    "                if(HRV_sampling_iter>1):\n",
    "                    Running_Sum_HR = Running_Sum_HR + pow( ( 1/(float(row[1]))-1/(prev_HR) ), 2)\n",
    "                \n",
    "                    Time_interval = float(row[0]) - df_HR.iloc[line_count-HRV_sampling_iter]['Time']\n",
    "                    #note: large gaps in data, such as HR taken on different days, need to be removed\n",
    "                    #hours to minutes\n",
    "                    Time_interval_hours = (Time_interval-Time_interval%100)*60/100\n",
    "                    #parse the minutes\n",
    "                    Time_interval_minutes = Time_interval%100\n",
    "                \n",
    "                    HRV =60000*pow((Running_Sum_HR)/HRV_sampling_iter, 0.5)\n",
    "               \n",
    "                    if(Time_interval_hours + Time_interval_minutes > HR_sampling_interval):\n",
    "                        #To account for sometimes irregular measurements a normalizing factor is used\n",
    "                        n_factor = HR_sampling_interval/(Time_interval_hours + Time_interval_minutes)\n",
    "                        HRV = HRV*n_factor\n",
    "                        df_HRV = df_HRV.append({t:float(row[0]),h:HRV}, ignore_index=True )\n",
    "                        HRV_sampling_iter=0\n",
    "                        Running_Sum_HR=0\n",
    "                if(line_count>0): \n",
    "                    prev_HR = float(row[1])\n",
    "                HRV_sampling_iter +=1\n",
    "                line_count +=1\n",
    "            \n",
    "    #df_HR.plot(kind='scatter', x='Time', y='HR')\n",
    "    #df_HRV.plot(kind='scatter', x='Time', y='HRV')\n",
    "        dfs_HRV.append(df_HRV)\n",
    "    #print(df_HRV['HRV'].describe())\n",
    "        timeStamp_S +=1\n",
    "    return dfs_HRV\n",
    "\n",
    "#____Main______\n",
    "TimeStamp_S =20200711.0\n",
    "TimeStamp_E =20200718.0\n",
    "hr_source =r\"C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\By Day\\Heart_Rate_\"\n",
    "HrV_dF =import_HRV(hr_source, TimeStamp_S, TimeStamp_E) #HrV_dF[n] n>0 now being continuous HRV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.55179808058973\n"
     ]
    }
   ],
   "source": [
    "ez = []\n",
    "for i in range(len(HrV_dF)):\n",
    "    if( i>0 and i<(len(HrV_dF)-1)):\n",
    "        ez += [[HrV_dF[i].iloc[2][t], HrV_dF[i].mean()[h]]]\n",
    "print(ez[3][1])\n",
    "#print(ez.loc[1][t])\n",
    "#print(ez[t][1])\n",
    "#print(ez[h][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Time        HRV\n",
      "0  2.020071e+11  [0, 1, 0]\n",
      "1  2.020071e+11  [0, 1, 0]\n",
      "2  2.020071e+11  [0, 0, 0]\n",
      "3  2.020071e+11  [1, 1, 1]\n",
      "4  2.020071e+11  [1, 1, 0]\n",
      "5  2.020072e+11  [0, 1, 1]\n",
      "[[202007101302.0, 46.432788566972754], [202007110052.0, 47.80279551414721], [202007120100.0, 35.62239036299937], [202007130637.0, 64.55179808058973], [202007140059.0, 61.671303436511884], [202007150121.0, 48.179099602208886]]\n"
     ]
    }
   ],
   "source": [
    "#This function encodes a dataframe of HRV data in 3 binary by time\n",
    "def encode_HRV(ez):\n",
    "    SCALE = [40,44,48,52,56,60,64]\n",
    " \n",
    "    for i in range(len(ez)):\n",
    "        if(ez[i][1]<=SCALE[0]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,0,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,0,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[0] and ez[i][1]<=SCALE[1]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,0,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,0,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[1] and ez[i][1]<=SCALE[2]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,1,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,1,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[2] and ez[i][1]<=SCALE[3]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,1,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,1,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[3] and ez[i][1]<=SCALE[4]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,0,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,0,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[4] and ez[i][1]<=SCALE[5]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,0,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,0,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[5] and ez[i][1]<=SCALE[6]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,1,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,1,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[6]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,1,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,1,1]},ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "#_______Main____\n",
    "e=encode_HRV(ez)\n",
    "print(e)\n",
    "print(ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0], [0, 1, 0], [0, 0, 0], [1, 1, 1], [1, 1, 0], [0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "e_e = [e[h][0]]\n",
    "for i in range(len(e[h]) -1):\n",
    "    e_e += [e[h][i+1]]\n",
    "print(e_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.74900000000001, 0, 0.2353067468867503, 538.2353067468867]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "#run this script for each of the days ez[1][0] to ez[6][0]\n",
    "time_Search = ez[0][0]\n",
    "time_Search_stamp = (time_Search-time_Search%10000)/10000\n",
    "readFile_location =r\"C:\\Users\\admin\\anaconda3\\01 Projects\\02 HEART RATE\\By Day\\\\\"\n",
    "total = []\n",
    "data_count = 0\n",
    "for j in range(len(dataSource)):\n",
    "    file = Path(readFile_location+dataSource[j]+str(time_Search_stamp)+\".csv\")\n",
    "    if file.is_file():\n",
    "        with open(readFile_location+dataSource[j]+str(time_Search_stamp)+\".csv\", mode='r') as csv_file:\n",
    "    \n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count =0\n",
    "\n",
    "            for row in csv_reader:\n",
    "                if(line_count>0):\n",
    "                    data_count += float(row[1])\n",
    "                line_count +=1\n",
    "            \n",
    "    else:\n",
    "        data_count =0\n",
    "    total += [data_count]    \n",
    "print(total)        #Set the input variable to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.74900000000001, 0, 0.2353067468867503, 538.2353067468867], [21.492, 0, 0.21240253294534364, 432.21240253294536], [12.974000000000004, 13.15201776887913, 13.42767002460025, 628.4276700246003], [1.446, 0, 0.5390392458158961, 1153.539039245816], [10.321000000000002, 0, 1.604717656151466, 2595.6047176561515], [203.24399999999974, 204.33408859576434, 207.74473881057656, 4716.744738810577]]\n"
     ]
    }
   ],
   "source": [
    "# For visibility the output of the above scripts across all days of interrest is printed below\n",
    "Day = [[23.74900000000001, 0, 0.2353067468867503, 538.2353067468867]]\n",
    "Day += [[21.492, 0, 0.21240253294534364, 432.21240253294536]]\n",
    "Day += [[12.974000000000004, 13.15201776887913, 13.42767002460025, 628.4276700246003]]\n",
    "Day += [[1.446, 0, 0.5390392458158961, 1153.539039245816]]\n",
    "Day += [[10.321000000000002, 0, 1.604717656151466, 2595.6047176561515]]\n",
    "Day += [[203.24399999999974, 204.33408859576434, 207.74473881057656, 4716.744738810577]]\n",
    "print(Day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#expected_output = np.array([[0],[1],[1],[0]])\n",
    "#inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "#print([[0],[1],[1],[0]])\n",
    "#print(expected_output)\n",
    "#print([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "#Expected_Output =[ [test1_day1.loc[0]['HRV'][0],test1_day1.loc[0]['HRV'][1],test1_day1.loc[0]['HRV'][2]] ]\n",
    "#for i in range(len(test1_day1)):\n",
    "    #if i>0:\n",
    "        #Expected_Output.append([test1_day1.loc[i]['HRV'][0],test1_day1.loc[i]['HRV'][1],test1_day1.loc[i]['HRV'][2]])\n",
    "#EXPECTED_OUTPUT=np.array(Expected_Output)\n",
    "#print(EXPECTED_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.48169153 0.43473697 0.36095586 0.60841271] [0.27759418 0.21707605 0.23961015 0.18358522] [0.21072984 0.39805345 0.40883371 0.61911679] [0.59158686 0.14310593 0.91511701 0.26869498]\n",
      "Initial hidden biases: [0.81318633 0.01659907 0.48855141 0.86924556]\n",
      "Initial output weights: [0.61414444 0.46024966 0.48857675] [0.11258243 0.00647757 0.22499276] [0.24981925 0.14474273 0.63444114] [0.06724253 0.80656674 0.1025427 ]\n",
      "Initial output biases: [0.28379102 0.24737542 0.77392697]\n",
      "Final hidden weights: [0.48169153 0.43473697 0.36095586 0.60841271] [0.27759418 0.21707605 0.23961015 0.18358522] [0.21072984 0.39805345 0.40883371 0.61911679] [0.59158686 0.14310593 0.91511701 0.26869498]\n",
      "Final hidden bias: [0.81318633 0.01659907 0.48855141 0.86924556]\n",
      "Final output weights: [ 0.20999907  0.44905482 -0.09494875] [-0.29156294 -0.00471727 -0.35853274] [-0.15432612  0.13354789  0.05091564] [-0.33690284  0.79537189 -0.4809828 ]\n",
      "Final output bias: [-0.12035435  0.23618058  0.19040147]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.33333333 0.83333333 0.33333333] [0.33333333 0.83333333 0.33333333] [0.33333333 0.83333333 0.33333333] [0.33333333 0.83333333 0.33333333] [0.33333333 0.83333333 0.33333333] [0.33333333 0.83333333 0.33333333]\n",
      "[[0, 1, 0], [0, 1, 0], [0, 0, 0], [1, 1, 1], [1, 1, 0], [0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array(Day)\n",
    "expected_output = np.array(e_e)\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 4,4,3 #originally 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "    #Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    output_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    #Backpropagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    #Updating Weights and Biases\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)\n",
    "print(e_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The issue of undertraining the network is exemplified above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
