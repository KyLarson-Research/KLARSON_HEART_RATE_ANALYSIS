{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kyle Larson\n",
    "# File Name: OVERTRAINED.ipynb\n",
    "# License: GPL 3\n",
    "# Objective: The objective of this document is to demonstrate a simple neural network\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "#This function converts date and time from 'dd-Mth-yyyy hh:mm' to 'yyyymmddhhmm'\n",
    "def integer_Date_Time(string_1):\n",
    "    months = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "    string_2 =re.search(r'\\d+', string_1).group()\n",
    "    integer_date_time =int(string_2)*10000\n",
    "    for i in range(3):\n",
    "        string_1 = string_1.replace(string_2,'')\n",
    "        if(re.search(r'\\d+', string_1)):\n",
    "            string_2 = re.search(r'\\d+', string_1).group()\n",
    "        if i==0:\n",
    "            integer_date_time +=int(string_2)*100000000\n",
    "        if i==1:\n",
    "            integer_date_time +=int(string_2)*100\n",
    "        if i==2:\n",
    "            integer_date_time +=int(string_2)\n",
    "            regex = r'(?<=-)([\\w\\.-]+)- :(\\d+)'\n",
    "            match = re.search(regex, string_1)\n",
    "            if match: \n",
    "                for j in range(len(months)):\n",
    "                    if(re.match(match.group(1), months[j])):\n",
    "                        integer_date_time+=(j+1)*1000000\n",
    "    return integer_date_time\n",
    "\n",
    "#This function cleans Active Calories, Cycling Distance, Distance and Steps files\n",
    "#reading their raw data and writing it to smaller tidier files by day\n",
    "def clean_ACCDDS(data_source, i_loc, o_loc):\n",
    "    d ={ 'Time':[0] , data_source:[0] }\n",
    "    df = pandas.DataFrame(d, columns=['Time', data_source])\n",
    "    \n",
    "    T ='Time'\n",
    "    D =data_source\n",
    "    line_count =0\n",
    "    start_file_index =0\n",
    "    Nextdate =0\n",
    "    date =0\n",
    "    with open(i_loc+data_source+\".csv\", mode='r') as csv_file:\n",
    "    \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count =0\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if(line_count>0):\n",
    "                df = df.append({T:integer_Date_Time(row[1]),D:float(row[2])}, ignore_index=True)\n",
    "                Nextdate = df.loc[line_count][0] - (df.loc[line_count][0])%10000\n",
    "                #print(str(integer_Date_Time(row[1]))+\", \"+row[2])\n",
    "                if(line_count>1 and Nextdate-date >= 10000):\n",
    "                    with open(o_loc+data_source+str(Nextdate/10000)+\".csv\", mode='w') as outf:\n",
    "                        i =start_file_index\n",
    "                        outf.write(\"Time, \"+data_source+\"\\n\")\n",
    "                        while(i<line_count):\n",
    "                            outf.write(str(df.loc[i][0])+\", \"+str(df.loc[i][1])+\"\\n\")\n",
    "                            i +=1\n",
    "                    start_file_index = line_count\n",
    "            line_count +=1\n",
    "            date = Nextdate\n",
    "    return\n",
    "\n",
    "\n",
    "#___MAIN____\n",
    "dataSource = ['Active Calories', 'Cycling Distance', 'Distance', 'Steps']\n",
    "O_loc =r'C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\By Day\\\\'\n",
    "I_loc =r'C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\\\'\n",
    "for i in range(len(dataSource)):\n",
    "    clean_ACCDDS(dataSource[i], I_loc, O_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t='Time'\n",
    "h='HRV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____Borrowed from FileName:HRV_NN.ipynb this function imports the desired output HRV data\n",
    "def import_HRV(HR_source, timeStamp_S, timeStamp_E):\n",
    "    HRV =0\n",
    "    Running_Sum_HR =0\n",
    "    HRV_sampling_iter =0\n",
    "    prev_HR =0\n",
    "    HR_sampling_interval =10\n",
    "    dfs_HRV =[pandas.DataFrame()]\n",
    "    while(timeStamp_S < timeStamp_E):\n",
    "        with open(HR_source+str(timeStamp_S)+\".csv\", mode='r') as csv_file:\n",
    "\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count =0\n",
    "            df_HR = pandas.DataFrame()\n",
    "            df_HRV = pandas.DataFrame()\n",
    "            HRV_sampling_iter=0\n",
    "            Running_Sum_HR=0\n",
    "            for row in csv_reader:\n",
    "                if(line_count >0):\n",
    "                    df_HR = df_HR.append({t:float(row[0]), 'HR':float(row[1])}, ignore_index=True)\n",
    "                if(HRV_sampling_iter>1):\n",
    "                    Running_Sum_HR = Running_Sum_HR + pow( ( 1/(float(row[1]))-1/(prev_HR) ), 2)\n",
    "                \n",
    "                    Time_interval = float(row[0]) - df_HR.iloc[line_count-HRV_sampling_iter]['Time']\n",
    "                    #note: large gaps in data, such as HR taken on different days, need to be removed\n",
    "                    #hours to minutes\n",
    "                    Time_interval_hours = (Time_interval-Time_interval%100)*60/100\n",
    "                    #parse the minutes\n",
    "                    Time_interval_minutes = Time_interval%100\n",
    "                \n",
    "                    HRV =60000*pow((Running_Sum_HR)/HRV_sampling_iter, 0.5)\n",
    "               \n",
    "                    if(Time_interval_hours + Time_interval_minutes > HR_sampling_interval):\n",
    "                        #To account for sometimes irregular measurements a normalizing factor is used\n",
    "                        n_factor = HR_sampling_interval/(Time_interval_hours + Time_interval_minutes)\n",
    "                        HRV = HRV*n_factor\n",
    "                        df_HRV = df_HRV.append({t:float(row[0]),h:HRV}, ignore_index=True )\n",
    "                        HRV_sampling_iter=0\n",
    "                        Running_Sum_HR=0\n",
    "                if(line_count>0): \n",
    "                    prev_HR = float(row[1])\n",
    "                HRV_sampling_iter +=1\n",
    "                line_count +=1\n",
    "            \n",
    "    #df_HR.plot(kind='scatter', x='Time', y='HR')\n",
    "    #df_HRV.plot(kind='scatter', x='Time', y='HRV')\n",
    "        dfs_HRV.append(df_HRV)\n",
    "    #print(df_HRV['HRV'].describe())\n",
    "        timeStamp_S +=1\n",
    "    return dfs_HRV\n",
    "\n",
    "#____Main______\n",
    "TimeStamp_S =20200711.0\n",
    "TimeStamp_E =20200718.0\n",
    "hr_source =r\"C:\\Users\\admin\\anaconda3\\01 PROJECTS\\02 HEART RATE\\By Day\\Heart_Rate_\"\n",
    "HrV_dF =import_HRV(hr_source, TimeStamp_S, TimeStamp_E) #HrV_dF[n] n>0 now being continuous HRV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.55179808058973\n"
     ]
    }
   ],
   "source": [
    "ez = []\n",
    "for i in range(len(HrV_dF)):\n",
    "    if( i>0 and i<(len(HrV_dF)-1)):\n",
    "        ez += [[HrV_dF[i].iloc[2][t], HrV_dF[i].mean()[h]]]\n",
    "print(ez[3][1])\n",
    "#print(ez.loc[1][t])\n",
    "#print(ez[t][1])\n",
    "#print(ez[h][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Time        HRV\n",
      "0  2.020071e+11  [0, 1, 0]\n",
      "1  2.020071e+11  [0, 1, 0]\n",
      "2  2.020071e+11  [0, 0, 0]\n",
      "3  2.020071e+11  [1, 1, 1]\n",
      "4  2.020071e+11  [1, 1, 0]\n",
      "5  2.020072e+11  [0, 1, 1]\n",
      "[[202007101302.0, 46.432788566972754], [202007110052.0, 47.80279551414721], [202007120100.0, 35.62239036299937], [202007130637.0, 64.55179808058973], [202007140059.0, 61.671303436511884], [202007150121.0, 48.179099602208886]]\n"
     ]
    }
   ],
   "source": [
    "#This function encodes a dataframe of HRV data in 3 binary by time\n",
    "def encode_HRV(ez):\n",
    "    SCALE = [40,44,48,52,56,60,64]\n",
    " \n",
    "    for i in range(len(ez)):\n",
    "        if(ez[i][1]<=SCALE[0]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,0,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,0,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[0] and ez[i][1]<=SCALE[1]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,0,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,0,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[1] and ez[i][1]<=SCALE[2]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,1,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,1,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[2] and ez[i][1]<=SCALE[3]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[0,1,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[0,1,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[3] and ez[i][1]<=SCALE[4]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,0,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,0,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[4] and ez[i][1]<=SCALE[5]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,0,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,0,1]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[5] and ez[i][1]<=SCALE[6]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,1,0]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,1,0]},ignore_index=True)\n",
    "        if(ez[i][1]>SCALE[6]):\n",
    "            if(i == 0): df_out = pandas.DataFrame({t:ez[i][0],h:[[1,1,1]]})\n",
    "            else: df_out = df_out.append({t:ez[i][0],h:[1,1,1]},ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "#_______Main____\n",
    "e=encode_HRV(ez)\n",
    "print(e)\n",
    "print(ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        HRV\n",
      "0   2.020071e+11  [0, 0, 0]\n",
      "1   2.020071e+11  [0, 1, 0]\n",
      "2   2.020071e+11  [0, 0, 1]\n",
      "3   2.020071e+11  [1, 1, 0]\n",
      "4   2.020071e+11  [1, 1, 1]\n",
      "..           ...        ...\n",
      "69  2.020071e+11  [0, 0, 0]\n",
      "70  2.020071e+11  [0, 0, 1]\n",
      "71  2.020071e+11  [1, 1, 1]\n",
      "72  2.020071e+11  [0, 0, 0]\n",
      "73  2.020071e+11  [0, 0, 0]\n",
      "\n",
      "[74 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "day = 5\n",
    "test1_day1 = eHRVdF[day]\n",
    "test1_day0 = eHRVdF[day-1]\n",
    "print(test1_day1.loc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "#print([[0],[1],[1],[0]])\n",
    "#print(expected_output)\n",
    "#print([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "#Expected_Output =[ [test1_day1.loc[0]['HRV'][0],test1_day1.loc[0]['HRV'][1],test1_day1.loc[0]['HRV'][2]] ]\n",
    "#for i in range(len(test1_day1)):\n",
    "    #if i>0:\n",
    "        #Expected_Output.append([test1_day1.loc[i]['HRV'][0],test1_day1.loc[i]['HRV'][1],test1_day1.loc[i]['HRV'][2]])\n",
    "#EXPECTED_OUTPUT=np.array(Expected_Output)\n",
    "#print(EXPECTED_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Calories6\n",
      "Distance21\n",
      "Steps22\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "time_Search = test1_day0.loc[1]['Time']\n",
    "time_Search_stamp = (time_Search-time_Search%10000)/10000\n",
    "readFile_location =r\"C:\\Users\\admin\\anaconda3\\01 Projects\\02 HEART RATE\\By Day\\\\\"\n",
    "for j in range(len(dataSource)):\n",
    "    file = Path(readFile_location+dataSource[j]+str(time_Search_stamp)+\".csv\")\n",
    "    if file.is_file():\n",
    "        with open(readFile_location+dataSource[j]+str(time_Search_stamp)+\".csv\", mode='r') as csv_file:\n",
    "    \n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count =0\n",
    "\n",
    "            for row in csv_reader:\n",
    "                #if(line_count>0):\n",
    "                line_count +=1\n",
    "            print(dataSource[j]+str(line_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202007120019.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.23958466 0.52927662] [0.58024919 0.44905656]\n",
      "Initial hidden biases: [0.40877091 0.15095802]\n",
      "Initial output weights: [0.97842112] [0.78358121]\n",
      "Initial output biases: [0.51151716]\n",
      "Final hidden weights: [5.8975741  3.10911501] [5.89639697 3.10900516]\n",
      "Final hidden bias: [-1.98213287 -4.64255323]\n",
      "Final output weights: [6.53359328] [-6.55796747]\n",
      "Final output bias: [-3.07075352]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.08770912] [0.89759414] [0.89759803] [0.12229463]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 4,4,3 #originally 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "    #Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    output_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    #Backpropagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    #Updating Weights and Biases\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
